{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Text Summarization - NLP.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sas7nfOoFcux"
      },
      "source": [
        "## input text article\n",
        "article_text=\"Just what is agility in the context of software engineering work? Ivar Jacobson [Jac02a] provides a useful discussion: Agility  has become today’s buzzword when describing a modern software process. Everyone is agile. An agile team is a nimble team able to appropriately respond to changes. Change is what software development is very much about. Changes in the software being built, changes to the team members, changes because of new technology, changes of all kinds that may have an impact on the product they build or the project that creates the product. Support for changes should be built-in everything we do in software, something we embrace because it is the heart and soul of software. An agile team recognizes that software is developed by individuals working in teams and that the skills of these people, their ability to collaborate is at the core for the success of the project.In Jacobson’s view, the pervasiveness of change is the primary driver for agility. Software engineers must be quick on their feet if they are to accommodate the rapid changes that Jacobson describes.  But agility is more than an effective response to change. It also encompasses the philosophy espoused in the manifesto noted at the beginning of this chapter. It encourages team structures and attitudes that make communication (among team members, between technologists and business people, between software engineers and their managers) more facile. It emphasizes rapid delivery of operational software and deemphasizes the importance of intermediate work products (not always a good thing); it adopts the customer as a part of the development team and works to eliminate the “us and them” attitude that continues to pervade many software projects; it recognizes that planning in an uncertain world has its limits and that a project plan must be ﬂ exible.  Agility can be applied to any software process. However, to accomplish this, it is essential that the process be designed in a way that allows the project team to adapt tasks and to streamline them, conduct planning in a way that understands the ﬂ uidity of an agile development approach, eliminate all but the most essential work products and keep them lean, and emphasize an incremental delivery strategy that gets working software to the customer as rapidly as feasible for the product type and operational environment. \""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmHoIEzMstc"
      },
      "source": [
        "article_text ='We use the method word_tokenize() to split a sentence into words. The output of word tokenization can be converted to Data Frame for better text understanding in machine learning applications. It can also be provided as input for further text cleaning steps such as punctuation removal, numeric character removal or stemming. Machine learning models need numeric data to be trained and make a prediction. Word tokenization becomes a crucial part of the text (string) to numeric data conversion. Please read about Bag of Words or CountVectorizer. Please refer to below word tokenize NLTK example to understand the theory better.'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33hJZI_rNF-w"
      },
      "source": [
        "article_text = 'Text summarization is the process of shortening long pieces of text while preserving key information content and overall meaning, to create a subset (a summary) that represents the most important or relevant information within the Text. An example of Text summarization problem is news article summarization, which attempts to automatically produce an abstract from a given article. Sometimes one might be interested in generating a summary from a single source article, while others can use multiple source articles (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary. An example for this is App called inShorts, which summarizes news articles into 60 words.'"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7F3DC_nFcu6"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrA5vM7nFcu-"
      },
      "source": [
        "import re\n",
        "import nltk"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWIJosiYFcu_"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "777jvAumFcvB",
        "outputId": "16a6af8f-e0df-44c6-bd0e-70be0bfc6cfe"
      },
      "source": [
        "article_text = article_text.lower()\n",
        "article_text"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'text summarization is the process of shortening long pieces of text while preserving key information content and overall meaning, to create a subset (a summary) that represents the most important or relevant information within the text. an example of text summarization problem is news article summarization, which attempts to automatically produce an abstract from a given article. sometimes one might be interested in generating a summary from a single source article, while others can use multiple source articles (for example, a cluster of articles on the same topic). this problem is called multi-document summarization. a related application is summarizing news articles. imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary. an example for this is app called inshorts, which summarizes news articles into 60 words.'"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "aSn9AC7BFcvE",
        "outputId": "e4888402-84e3-48a2-e438-515b3b85ad18"
      },
      "source": [
        "# remove spaces, punctuations and numbers\n",
        "clean_text = re.sub('[^a-zA-Z]', ' ', article_text)\n",
        "clean_text = re.sub('\\s+', ' ', clean_text)\n",
        "clean_text"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'text summarization is the process of shortening long pieces of text while preserving key information content and overall meaning to create a subset a summary that represents the most important or relevant information within the text an example of text summarization problem is news article summarization which attempts to automatically produce an abstract from a given article sometimes one might be interested in generating a summary from a single source article while others can use multiple source articles for example a cluster of articles on the same topic this problem is called multi document summarization a related application is summarizing news articles imagine a system which automatically pulls together news articles on a given topic from the web and concisely represents the latest news as a summary an example for this is app called inshorts which summarizes news articles into words '"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1sMnXk_G8x_",
        "outputId": "12fc2d0b-1337-4078-ec4a-fb2650fbcec2"
      },
      "source": [
        "## run this cell once to download stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cqvSN1bFcvF",
        "outputId": "0f9f5f7f-e690-46f0-d41a-24263c8b1541"
      },
      "source": [
        "# split into sentence list\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "sentence_list"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text summarization is the process of shortening long pieces of text while preserving key information content and overall meaning, to create a subset (a summary) that represents the most important or relevant information within the text.',\n",
              " 'an example of text summarization problem is news article summarization, which attempts to automatically produce an abstract from a given article.',\n",
              " 'sometimes one might be interested in generating a summary from a single source article, while others can use multiple source articles (for example, a cluster of articles on the same topic).',\n",
              " 'this problem is called multi-document summarization.',\n",
              " 'a related application is summarizing news articles.',\n",
              " 'imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.',\n",
              " 'an example for this is app called inshorts, which summarizes news articles into 60 words.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJKV9dwPFcvH"
      },
      "source": [
        "## run this cell once to download stopwords\n",
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAF6wLT3FcvI"
      },
      "source": [
        "## Word Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0shysI7VFcvJ"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(clean_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies:\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP14VAINFcvK"
      },
      "source": [
        "maximum_frequency = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies:\n",
        "    word_frequencies[word] = word_frequencies[word] / maximum_frequency"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDv30GzKFcvL"
      },
      "source": [
        "## Calculate Sentence Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcuj-aSZFcvM"
      },
      "source": [
        "sentence_scores = {}\n",
        "\n",
        "for sentence in sentence_list:\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        if word in word_frequencies and len(sentence.split(' ')) < 30:\n",
        "            if sentence not in sentence_scores:\n",
        "                sentence_scores[sentence] = word_frequencies[word]\n",
        "            else:\n",
        "                sentence_scores[sentence] += word_frequencies[word]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPxT8X9IFcvN",
        "outputId": "4dc42908-8962-4107-d44a-05f61d0aae88"
      },
      "source": [
        "word_frequencies"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abstract': 0.2,\n",
              " 'app': 0.2,\n",
              " 'application': 0.2,\n",
              " 'article': 0.6,\n",
              " 'articles': 1.0,\n",
              " 'attempts': 0.2,\n",
              " 'automatically': 0.4,\n",
              " 'called': 0.4,\n",
              " 'cluster': 0.2,\n",
              " 'concisely': 0.2,\n",
              " 'content': 0.2,\n",
              " 'create': 0.2,\n",
              " 'document': 0.2,\n",
              " 'example': 0.6,\n",
              " 'generating': 0.2,\n",
              " 'given': 0.4,\n",
              " 'imagine': 0.2,\n",
              " 'important': 0.2,\n",
              " 'information': 0.4,\n",
              " 'inshorts': 0.2,\n",
              " 'interested': 0.2,\n",
              " 'key': 0.2,\n",
              " 'latest': 0.2,\n",
              " 'long': 0.2,\n",
              " 'meaning': 0.2,\n",
              " 'might': 0.2,\n",
              " 'multi': 0.2,\n",
              " 'multiple': 0.2,\n",
              " 'news': 1.0,\n",
              " 'one': 0.2,\n",
              " 'others': 0.2,\n",
              " 'overall': 0.2,\n",
              " 'pieces': 0.2,\n",
              " 'preserving': 0.2,\n",
              " 'problem': 0.4,\n",
              " 'process': 0.2,\n",
              " 'produce': 0.2,\n",
              " 'pulls': 0.2,\n",
              " 'related': 0.2,\n",
              " 'relevant': 0.2,\n",
              " 'represents': 0.4,\n",
              " 'shortening': 0.2,\n",
              " 'single': 0.2,\n",
              " 'sometimes': 0.2,\n",
              " 'source': 0.4,\n",
              " 'subset': 0.2,\n",
              " 'summarization': 0.8,\n",
              " 'summarizes': 0.2,\n",
              " 'summarizing': 0.2,\n",
              " 'summary': 0.6,\n",
              " 'system': 0.2,\n",
              " 'text': 0.8,\n",
              " 'together': 0.2,\n",
              " 'topic': 0.4,\n",
              " 'use': 0.2,\n",
              " 'web': 0.2,\n",
              " 'within': 0.2,\n",
              " 'words': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLVFwlopFcvN",
        "outputId": "81777b5f-81b0-44bd-b4d7-a825c8e8704d"
      },
      "source": [
        "sentence_scores"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a related application is summarizing news articles.': 2.6,\n",
              " 'an example for this is app called inshorts, which summarizes news articles into 60 words.': 3.8000000000000003,\n",
              " 'an example of text summarization problem is news article summarization, which attempts to automatically produce an abstract from a given article.': 7.000000000000001,\n",
              " 'imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.': 6.6000000000000005,\n",
              " 'this problem is called multi-document summarization.': 1.6}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqYPcPlNFcvO"
      },
      "source": [
        "## Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcvbse4UFcvO",
        "outputId": "893db966-3c44-45b4-ce7e-e851ebe8a917"
      },
      "source": [
        "# get top 5 sentences\n",
        "import heapq\n",
        "summary = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "print(\" \".join(summary))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "an example of text summarization problem is news article summarization, which attempts to automatically produce an abstract from a given article. imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiO44tY1M469"
      },
      "source": [
        ""
      ],
      "execution_count": 48,
      "outputs": []
    }
  ]
}